{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c27a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data set from file: datasets/data_wrangling_rl1_2021_u6773547.csv\n",
      "  Header line: ['rec_id', 'first_name', 'middle_name', 'last_name', 'gender', 'current_age', 'birth_date', 'street_address', 'suburb', 'postcode', 'state', 'phone', 'email']\n",
      "  Record identifier attribute: rec_id\n",
      "  Attributes to use:\n",
      "    first_name\n",
      "    middle_name\n",
      "    last_name\n",
      "    gender\n",
      "    birth_date\n",
      "    street_address\n",
      "    suburb\n",
      "    postcode\n",
      "    state\n",
      "    phone\n",
      "\n",
      "Load data set from file: datasets/data_wrangling_rl2_2021_u6773547.csv\n",
      "  Header line: ['rec_id', 'first_name', 'middle_name', 'last_name', 'gender', 'current_age', 'birth_date', 'street_address', 'suburb', 'postcode', 'state', 'phone', 'email']\n",
      "  Record identifier attribute: rec_id\n",
      "  Attributes to use:\n",
      "    first_name\n",
      "    middle_name\n",
      "    last_name\n",
      "    gender\n",
      "    birth_date\n",
      "    street_address\n",
      "    suburb\n",
      "    postcode\n",
      "    state\n",
      "    phone\n",
      "\n",
      "Load truth data from file: datasets/data_wrangling_rlgt_2021_u6773547.csv\n",
      "  Loaded 10000 true matching record pairs\n",
      "\n",
      "Run phonetic blocking:\n",
      "  List of blocking key attributes: [3, 1, 6, 4]\n",
      "  Number of records to be blocked: 20000\n",
      "\n",
      "Run phonetic blocking:\n",
      "  List of blocking key attributes: [3, 1, 6, 4]\n",
      "  Number of records to be blocked: 20000\n",
      "\n",
      "Statistics of the generated blocks:\n",
      "Dataset A number of blocks generated: 19694\n",
      "    Minimum block size: 1\n",
      "    Average block size: 1.02\n",
      "    Maximum block size: 4\n",
      "\n",
      "Dataset B number of blocks generated: 19824\n",
      "    Minimum block size: 1\n",
      "    Average block size: 1.01\n",
      "    Maximum block size: 3\n",
      "\n",
      "Compare 19694 blocks from dataset A with 19824 blocks from dataset B\n",
      "  Compared 6400 record pairs\n",
      "\n",
      "Supervised decision tree classification of 6400 record pairs\n",
      "  Number of training records and features: 6400 / 6\n",
      "  Number of positive and negative training records: 5905 / 495\n",
      "\n",
      "  Classifier 0 gets 2134 correct and 0 wrong\n",
      "  Classifier 1 gets 2134 correct and 0 wrong\n",
      "  Classifier 2 gets 2133 correct and 1 wrong\n",
      "\n",
      "  Classified 5905 record pairs as matches and 495 as non-matches\n",
      "\n",
      "Blocking evaluation:\n",
      "  Reduction ratio:    1.0000\n",
      "  Pairs completeness: 0.5905\n",
      "  Pairs quality:      0.9227\n",
      "\n",
      "Calculating confusion matrix using 5905 classified matches, 495 classified non-matches, and 10000 true matches\n",
      "  TP=5905, FP=0, FN=4095, TN=399990000\n",
      "\n",
      "Linkage evaluation:\n",
      "  Accuracy:    1.0000\n",
      "  Precision:   1.0000\n",
      "  Recall:      0.5905\n",
      "  F-measure:   0.7425\n",
      "\n",
      "Total runtime required for linkage: 3.3403 sec\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Record linkage software for the COMP3430/COMP8430 Data Wrangling course, \n",
    "# 2021.\n",
    "# Version 1.0\n",
    "#\n",
    "# Copyright (C) 2021 the Australian National University and\n",
    "# others. All Rights Reserved.\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"Main module for linking records from two files.\n",
    "\n",
    "   This module calls the necessary modules to perform the functionalities of\n",
    "   the record linkage process.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Import necessary modules (Python standard modules first, then other modules)\n",
    "\n",
    "import time\n",
    "\n",
    "import loadDataset\n",
    "import blocking\n",
    "import comparison\n",
    "import classification\n",
    "import evaluation\n",
    "\n",
    "# =============================================================================\n",
    "# Variable names for loading datasets\n",
    "\n",
    "# ******** Uncomment to select a pair of datasets **************\n",
    "\n",
    "datasetA_name = 'datasets/data_wrangling_rl1_2021_u6773547.csv'\n",
    "datasetB_name = 'datasets/data_wrangling_rl2_2021_u6773547.csv'\n",
    "\n",
    "#datasetA_name = 'datasets/little-dirty-A-10000.csv'\n",
    "#datasetB_name = 'datasets/little-dirty-B-10000.csv'\n",
    "\n",
    "headerA_line   = True  # Dataset A header line available - True or Flase\n",
    "headerB_line   = True  # Dataset B header line available - True or Flase\n",
    "\n",
    "# Name of the corresponding file with true matching record pair\n",
    "\n",
    "# ***** Uncomment a file name corresponding to your selected datasets *******\n",
    "\n",
    "truthfile_name = 'datasets/data_wrangling_rlgt_2021_u6773547.csv'\n",
    "\n",
    "#truthfile_name = 'datasets/little-dirty-true-matches-10000.csv'\n",
    "\n",
    "# The two attribute numbers that contain the record identifiers\n",
    "#\n",
    "rec_idA_col = 0\n",
    "rec_idB_col = 0\n",
    "\n",
    "# The list of attributes to be used either for blocking or linking\n",
    "#\n",
    "# For the example data sets used in COMP8430 data wrangling in 2021:\n",
    "# \n",
    "#  0: rec_id\n",
    "#  1: first_name\n",
    "#  2: middle_name -\n",
    "#  3: last_name\n",
    "#  4: gender\n",
    "#  5: current_age -\n",
    "#  6: birth_date -\n",
    "#  7: street_address -\n",
    "#  8: suburb\n",
    "#  9: postcode -\n",
    "# 10: state\n",
    "# 11: phone -\n",
    "# 12: email -\n",
    "\n",
    "attrA_list    = [1,2,3,4,6,7,8,9,10,11]\n",
    "attrB_list    = [1,2,3,4,6,7,8,9,10,11]\n",
    "\n",
    "# ******** In lab 3, explore different attribute sets for blocking ************\n",
    "\n",
    "# The list of attributes to use for blocking (all must occur in the above\n",
    "# attribute lists)\n",
    "#\n",
    "blocking_attrA_list = [3,4,10]\n",
    "blocking_attrB_list = [3,4,10]\n",
    "\n",
    "# ******** In lab 4, explore different comparison functions for different  ****\n",
    "# ********           attributes                                            ****\n",
    "\n",
    "# The list of tuples (comparison function, attribute number in record A,\n",
    "# attribute number in record B)\n",
    "#\n",
    "exact_comp_funct_list = [(comparison.exact_comp, 1, 1),  # First name\n",
    "                         (comparison.exact_comp, 2, 2),  # Middle name\n",
    "                         (comparison.exact_comp, 3, 3),  # Last name\n",
    "                         (comparison.exact_comp, 8, 8),  # Suburb\n",
    "                         (comparison.exact_comp,10,10),  # State\n",
    "                         ]\n",
    "\n",
    "approx_comp_funct_list = [(comparison.jaccard_comp, 1, 1),        # First name\n",
    "                          (comparison.dice_comp, 2, 2),           # Middle name\n",
    "                          (comparison.jaro_winkler_comp, 3, 3),   # Last name\n",
    "                          (comparison.bag_dist_sim_comp, 7, 7),   # Address\n",
    "                          (comparison.edit_dist_sim_comp, 8, 8),  # Suburb\n",
    "                          (comparison.exact_comp,10,10),          # State\n",
    "                         ]\n",
    "\n",
    "# =============================================================================\n",
    "#\n",
    "# Step 1: Load the two datasets from CSV files\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "recA_dict = loadDataset.load_data_set(datasetA_name, rec_idA_col, \\\n",
    "                                      attrA_list, headerA_line)\n",
    "recB_dict = loadDataset.load_data_set(datasetB_name, rec_idB_col, \\\n",
    "                                      attrB_list, headerB_line)\n",
    "\n",
    "# Load data set of true matching pairs\n",
    "#\n",
    "true_match_set = loadDataset.load_truth_data(truthfile_name)\n",
    "\n",
    "loading_time = time.time() - start_time\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 2: Block the datasets\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Select one blocking technique\n",
    "\n",
    "# No blocking (all records in one block)\n",
    "#\n",
    "#blockA_dict = blocking.noBlocking(recA_dict)\n",
    "#blockB_dict = blocking.noBlocking(recB_dict)\n",
    "\n",
    "# Simple attribute-based blocking\n",
    "#\n",
    "#blockA_dict = blocking.simpleBlocking(recA_dict, blocking_attrA_list)\n",
    "#blockB_dict = blocking.simpleBlocking(recB_dict, blocking_attrB_list)\n",
    "\n",
    "# Phonetic (Soundex) based blocking\n",
    "#\n",
    "blockA_dict = blocking.phoneticBlocking(recA_dict, blocking_attrA_list)\n",
    "blockB_dict = blocking.phoneticBlocking(recB_dict, blocking_attrB_list)\n",
    "\n",
    "# Statistical linkage key (SLK-581) based blocking\n",
    "#\n",
    "fam_name_attr_ind = 3\n",
    "giv_name_attr_ind = 10\n",
    "dob_attr_ind      = 6\n",
    "gender_attr_ind   = 4\n",
    "\n",
    "#blockA_dict = blocking.slkBlocking(recA_dict, fam_name_attr_ind, \\\n",
    "#                                   giv_name_attr_ind, dob_attr_ind, \\\n",
    "#                                   gender_attr_ind)\n",
    "#blockB_dict = blocking.slkBlocking(recB_dict, fam_name_attr_ind, \\\n",
    "#                                   giv_name_attr_ind, dob_attr_ind, \\\n",
    "#                                   gender_attr_ind)\n",
    "\n",
    "blocking_time = time.time() - start_time\n",
    "\n",
    "# Print blocking statistics\n",
    "#\n",
    "blocking.printBlockStatistics(blockA_dict, blockB_dict)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 3: Compare the candidate pairs\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sim_vec_dict = comparison.compareBlocks(blockA_dict, blockB_dict, \\\n",
    "                                        recA_dict, recB_dict, \\\n",
    "                                        approx_comp_funct_list)\n",
    "\n",
    "comparison_time = time.time() - start_time\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 4: Classify the candidate pairs\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 方法一 Exact matching based classification\n",
    "#\n",
    "# class_match_set, class_nonmatch_set = \\\n",
    "#             classification.exactClassify(sim_vec_dict)\n",
    "\n",
    "# *********** In lab 5, explore different similarity threshold values *********\n",
    "\n",
    "# 方法二 Similarity threshold based classification\n",
    "#\n",
    "#sim_threshold = 0.01\n",
    "#class_match_set, class_nonmatch_set = \\\n",
    "#             classification.thresholdClassify(sim_vec_dict, sim_threshold)\n",
    "\n",
    "# 方法三 Minimum similarity threshold based classification\n",
    "#\n",
    "#min_sim_threshold = 0.99\n",
    "#class_match_set, class_nonmatch_set = \\\n",
    "#             classification.minThresholdClassify(sim_vec_dict,\n",
    "#                                                 min_sim_threshold)\n",
    "\n",
    "# *********** In lab 6, explore different weight vectors **********************\n",
    "\n",
    "# 方法四 Weighted similarity threshold based classification\n",
    "#\n",
    "#weight_vec = [1.0] * len(approx_comp_funct_list)\n",
    "\n",
    "# Lower weights for middle name and state\n",
    "#\n",
    "#weight_vec = [2.0, 1.0, 2.0, 2.0, 2.0, 1.0]\n",
    "\n",
    "#class_match_set, class_nonmatch_set = \\\n",
    "#             classification.weightedSimilarityClassify(sim_vec_dict,\n",
    "#                                                      weight_vec,\n",
    "#                                                       sim_threshold)\n",
    "\n",
    "# 方法五 A supervised decision tree classifier\n",
    "#\n",
    "class_match_set, class_nonmatch_set = \\\n",
    "           classification.supervisedMLClassify(sim_vec_dict, true_match_set)\n",
    "\n",
    "classification_time = time.time() - start_time\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 5: Evaluate the classification\n",
    "\n",
    "# Get the number of record pairs compared\n",
    "#\n",
    "num_comparisons = len(sim_vec_dict)\n",
    "\n",
    "# Get the number of total record pairs to compared if no blocking used\n",
    "#\n",
    "all_comparisons = len(recA_dict) * len(recB_dict)\n",
    "\n",
    "# Get the list of identifiers of the compared record pairs\n",
    "#\n",
    "cand_rec_id_pair_list = sim_vec_dict.keys()\n",
    "\n",
    "# Blocking evaluation\n",
    "#\n",
    "rr = evaluation.reduction_ratio(num_comparisons, all_comparisons)\n",
    "pc = evaluation.pairs_completeness(cand_rec_id_pair_list, true_match_set)\n",
    "pq = evaluation.pairs_quality(cand_rec_id_pair_list, true_match_set)\n",
    "\n",
    "print('Blocking evaluation:')\n",
    "print('  Reduction ratio:    %.4f' % (rr))\n",
    "print('  Pairs completeness: %.4f' % (pc))\n",
    "print('  Pairs quality:      %.4f' % (pq))\n",
    "print('')\n",
    "\n",
    "# Linkage evaluation\n",
    "#\n",
    "linkage_result = evaluation.confusion_matrix(class_match_set,\n",
    "                                             class_nonmatch_set,\n",
    "                                             true_match_set,\n",
    "                                             all_comparisons)\n",
    "\n",
    "accuracy =    evaluation.accuracy(linkage_result)\n",
    "precision =   evaluation.precision(linkage_result)\n",
    "recall    =   evaluation.recall(linkage_result)\n",
    "fmeasure  =   evaluation.fmeasure(linkage_result)\n",
    "\n",
    "print('Linkage evaluation:')\n",
    "print('  Accuracy:    %.4f' % (accuracy))\n",
    "print('  Precision:   %.4f' % (precision))\n",
    "print('  Recall:      %.4f' % (recall))\n",
    "print('  F-measure:   %.4f' % (fmeasure))\n",
    "print('')\n",
    "\n",
    "linkage_time = loading_time + blocking_time + comparison_time + \\\n",
    "               classification_time\n",
    "print('Total runtime required for linkage: %.4f sec' % (linkage_time))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# End of program.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
